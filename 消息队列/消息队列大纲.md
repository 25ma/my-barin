#知识大纲 #消息队列 

# 使用篇

## 消息队列的使用场景

### 使用场景

- 异步化，提升并行能力。
- 增加缓冲，提升系统可用性。
- 流量控制。
- 解耦。
- 生产者/消费者模型。
- 广播消息。
- 流数据处理。

### 弊端

同时我们也要认识到，消息队列也有它自身的一些问题和局限性，包括：

-   引入消息队列带来的延迟问题。
-   增加了系统的复杂度。
-   可能产生数据不一致的问题。如果需要强一致需要高代价补偿，如分布式事务，对账。

## 基于消息队列支持分布式事务

在实际应用中，比较常见的分布式事务实现有 2PC（Two-phase Commit，也叫二阶段提交）、TCC (Try-Confirm-Cancel) 和事务消息。每一种实现都有其特定的使用场景，也有各自的问题，都不是完美的解决方案。

事务消息需要消息队列提供相应的功能才能实现，Kafka 和 RocketMQ 都提供了事务相关功能：
![](https://varg-my-images.oss-cn-beijing.aliyuncs.com/img/20220530110727.png)

对于第 4 步的消息提交操作，如果出现失败，Kafka 和 RocketMQ 有不同的处理策略：
- Kafka：直接抛出异常，由用户进行处理。
- RocketMQ：增加了事务反查的机制。
	在提交或者回滚事务消息时发生网络异常，RocketMQ 的 Broker 没有收到提交或者回滚的请求，Broker 会定期去 Producer 上反查这个事务对应的本地事务的状态，然后根据反查结果决定提交或者回滚这个事务。
	
	为了支撑这个事务反查机制，业务代码需要实现一个反查本地事务状态的接口，告知 RocketMQ 本地事务是成功还是失败。

	![](https://varg-my-images.oss-cn-beijing.aliyuncs.com/img/20220530111046.png)

# 基础原理

## 消息队列设计考虑点

1. 基于异步的机制，减少同步阻塞。
2. 高效的网络 IO 模型，如 Netty/NIO。
3. 序列化与反序列化机制，需要在序列化复杂度，易读性，序列化速度以及序列化的大小之间作出平衡。
4. 数据的传输问题，需要处理数据的收发(毡包拆包问题：固定长度，分隔符，前置长度)，数据的单双工信道通信问题。

## 消息队列的模型

### 队列模型

队列模型在消息入队出队过程中，需要保证这些消息严格有序，按照什么顺序写进队列，必须按照同样的顺序从队列中读出来。

如果有多个生产者往同一个队列里面发送消息，这个队列中可以消费到的消息，就是这些生产者生产的所有消息的合集。消息的顺序就是这些生产者发送消息的自然顺序。如果有多个消费者接收同一个队列的消息，这些消费者之间实际上是竞争的关系，每个消费者只能收到队列中的一部分消息，也就是说任何一条消息只能被其中的一个消费者收到。

如果需要将一份消息数据分发给多个消费者，要求每个消费者都能收到全量的消息，这个时候，单个队列就满足不了需求。一个可行的解决方式是，为每个消费者创建一个单独的队列，让生产者发送多份。
![](https://varg-my-images.oss-cn-beijing.aliyuncs.com/img/20220527120014.png)

RabbitMQ 使用的就是队列模型，由 Exchange 决定将消息发送给哪些队列：

![](https://varg-my-images.oss-cn-beijing.aliyuncs.com/img/20220527120229.png)

### 发布订阅模型

#### 发布订阅模型机制

在发布 - 订阅模型中，消息的发送方称为发布者（Publisher），消息的接收方称为订阅者（Subscriber），服务端存放消息的容器称为主题（Topic）。发布者将消息发送到主题中，订阅者在接收消息之前需要先“订阅主题”。“订阅”在这里既是一个动作，同时还可以认为是主题在消费时的一个逻辑副本，每份订阅中，订阅者都可以接收到主题的所有消息。

![](https://varg-my-images.oss-cn-beijing.aliyuncs.com/img/20220527120027.png)

#### 发布订阅模型的消费组

![](https://varg-my-images.oss-cn-beijing.aliyuncs.com/img/20220527122610.png)

RocketMQ 中，订阅者的概念是通过消费组（Consumer Group）来体现的。每个消费组都消费主题中一份完整的消息，不同消费组之间消费进度彼此不受影响。也就是说，一条消息被 Consumer Group1 消费过，也会再给 Consumer Group2 消费。

消费组中包含多个消费者，同一个组内的消费者是竞争消费的关系，每个消费者负责消费组内的一部分消息。如果一条消息被消费者 Consumer1 消费了，那同组的其他消费者就不会再收到这条消息。

在 Topic 的消费过程中，由于消息需要被不同的组进行多次消费，所以消费完的消息并不会立即被删除，这就需要 RocketMQ 为每个消费组在每个队列上维护一个消费位置（Consumer Offset），这个位置之前的消息都被消费过，之后的消息都没有被消费过，每成功消费一条消息，消费位置就加一。这个消费位置是非常重要的概念，我们在使用消息队列的时候，丢消息的原因大多是由于消费位置处理不当导致的。

Kafka 的消息模型和 RocketMQ 是完全一样的，我刚刚讲的所有 RocketMQ 中对应的概念，和生产消费过程中的确认机制，都完全适用于 Kafka。唯一的区别是，在 Kafka 中，队列这个概念的名称不一样，Kafka 中对应的名称是“分区（Partition）”，含义和功能是没有任何区别的。

### 队列模型与发布订阅模型对比

生产者就是发布者，消费者就是订阅者，队列就是主题，并没有本质的区别。它们最大的区别其实就是，**一份消息数据能不能被消费多次的问题**。实际上，在发布 - 订阅模型中，如果只有一个订阅者，那它和队列模型就基本是一样的了。也就是说，发布 - 订阅模型在功能层面上是可以兼容队列模型的。现代的消息队列产品使用的消息模型大多是这种发布 - 订阅模型，当然也有例外。

# 高可靠

## 消息不丢失保证

![](https://varg-my-images.oss-cn-beijing.aliyuncs.com/img/20220530113439.png)

1. 生产阶段
	通过请求确认机制，当生产者发送消息后，需要等到消息队列返回确认发送成功的标识后才可认为消息发送成功。否则超时未收到消息或者发送失败时需要进行重试重新发送。如果由于网络抖动导致的确认丢失出现消息重复的情况，消费者需要有能力处理消息重复的场景。
2. 存储阶段
	如果需要保证消息百分百不丢失，则需要消息队列在收到消息后立马持久化到磁盘中。只有持久化成功后给生产者返回 ack 信号。
3. 消费阶段
	消费者也采用请求确认机制，只有当消费成功后才给队列返回成功的ack，若消费失败则不会删除消息以备重新消费。为了确认能做到这点，**消息队列通常在同一时刻会被某个消费者锁定，在锁定这段期间，其他消费者无法消费。**

## 消息幂等性保证

在 MQTT 协议中，给出了三种传递消息时能够提供的服务质量标准，这三种服务质量从低到高依次是：
- At most once: 至多一次。消息在传递时，最多会被送达一次。换一个说法就是，没什么消息可靠性保证，允许丢消息。一般都是一些对消息可靠性要求不太高的监控场景使用，比如每分钟上报一次机房温度数据，可以接受数据少量丢失。
- At least once: 至少一次。消息在传递时，至少会被送达一次。也就是说，不允许丢消息，但是允许有少量重复消息出现。
- Exactly once：恰好一次。消息在传递时，只会被送达一次，不允许丢失也不允许重复，这个是最高的等级。这个服务质量标准不仅适用于 MQTT，对所有的消息队列都是适用的。

我们现在常用的绝大部分消息队列提供的服务质量都是 At least once，包括 RocketMQ、RabbitMQ 和 Kafka 都是这样。也就是说，消息队列很难保证消息不重复。

### 幂等性解决方案

对于天然幂等性的操作，就算不进行额外处理也能保证数据准确性。如删除数据，将删除标记为置为 1，不管执行多少次都是一样的。

而对于非天然幂等性的，就需要在业务代码中进行额外处理，通常有以下几种解决措施：
1. 利用数据库的唯一约束实现幂等。
2. 为更新的数据设置前置条件，如版本号机制。
3. 记录并检查操作，可以利用全局唯一 ID 方式进行检查。
	- 全局唯一 ID 生成需要满足简单，高可用和高性能条件，这或多或少都会对性能做出一些牺牲。
	- 获取+检查+记录这三个操作必须是原子性的，否则会出现检查失效的情况。这就意味着要么将这三个操作用事务来完成，要么需要锁机制。这也会对性能造成一定影响。

## 消息积压处理

### 消息积压原因

- 生产者发送过快。
- 消费者消费过慢，除了正常消费慢之外，还需要考虑是否是消费失败导致重复消费的情况。

### 消息积压解决措施

- 进行消费端紧急扩容
	需要说明的是，**在队列数量没有变的情况下，单纯增加消费者数量是没有效果的**。因为一个队列在同一时刻对于一个消费组来说是只会有一个消费者的，消费组中消费者再多也没意义。因此要么是在生产端把消息发往多个队列，达到并行消费的目的。要么是从该队列中取出消息，再将它分发个多个队列，从而达到并行消费的目的。
- 将消息临时写入其他系统，如数据库中。先将消息接下来，后续再慢慢消费回去。
- 服务降级，保证系统正常运转，防止压垮系统。
- 若是消息生产速率过快，排查过快圆心，减少消息生产。

# 高性能

## Kafka 的高性能设计

1. 批量处理技术

	当调用 send () 方法发送一条消息之后，无论是同步发送还是异步发送，Kafka 都不会立即就把这条消息发送出去。它会先把这条消息，存放在内存中缓存起来，然后选择合适的时机把缓存中的所有消息组成一批，一次性发给 Broker。
	
	简单地说，就是攒一波一起发。在 Kafka 的服务端，Kafka 不会把一批消息再还原成多条消息，再一条一条地处理，这样太慢了。Kafka 这块儿处理的非常聪明，每批消息都会被当做一个“批消息”来处理。也就是说，在 Broker 整个处理流程中，无论是写入磁盘、从磁盘读出来、还是复制到其他副本这些流程中，批消息都不会被解开，一直是作为一条“批消息”来进行处理的。在消费时，消息同样是以批为单位进行传递的，Consumer 从 Broker 拉到一批消息后，在客户端把批消息解开，再一条一条交给用户代码处理。
	
	构建批消息和解开批消息分别在发送端和消费端的客户端完成，不仅减轻了 Broker 的压力，最重要的是减少了 Broker 处理请求的次数，提升了总体的处理能力。

	如果开启了压缩模式的话，那么压缩与解压的过程也是在发送端与客户端完成的，这也利用了批处理的优势。

1. 使用顺序读写提升磁盘 IO 性能

	Kafka 充分利用了磁盘顺序读写快于随机读写的特性。它的存储设计非常简单，对于每个分区，它把从 Producer 收到的消息，顺序地写入对应的 log 文件中，一个文件写满了，就开启一个新的文件这样顺序写下去。消费的时候，也是从某个全局的位置开始，也就是某一个 log 文件中的某个位置开始，顺序地把消息读出来。这样一个简单的设计，充分利用了顺序读写这个特性，极大提升了 Kafka 在使用磁盘时的 IO 性能。

1. 利用 PageCache 加速消息读写

	Kafka 在读写消息文件的时候，充分利用了 PageCache 的特性。一般来说，消息刚刚写入到服务端就会被消费，按照 LRU 的“优先清除最近最少使用的页”这种策略，读取的时候，对于这种刚刚写入的 PageCache，命中的几率会非常高。
	
	也就是说，大部分情况下，消费读消息都会命中 PageCache，带来的好处有两个：一个是读取的速度会非常快，另外一个是，给写入消息让出磁盘的 IO 资源，间接也提升了写入的性能。

1. ZeroCopy：零拷贝技术

	在服务端，处理消费的大致逻辑是这样的：
	1. 首先，从文件中找到消息数据，读到内存中。
	2. 然后，把消息通过网络发给客户端。
	
	这个过程中，数据实际上做了 2 次或者 3 次复制：
	1. 从文件复制数据到 PageCache 中，如果命中 PageCache，这一步可以省掉。
	2. 从 PageCache 复制到应用程序的内存空间中，也就是我们可以操作的对象所在的内存。
	3. 从应用程序的内存空间复制到 Socket 的缓冲区，这个过程就是我们调用网络应用框架的 API 发送数据的过程。
	
	Kafka 使用零拷贝技术可以把这个复制次数减少一次，上面的 2、3 步骤两次复制合并成一次复制。直接从 PageCache 中把数据复制到 Socket 缓冲区中，这样不仅减少一次数据复制，更重要的是，由于不用把数据复制到用户内存空间，DMA 控制器可以直接完成数据复制，不需要 CPU 参与，速度更快。
	
	如果你遇到这种从文件读出数据后再通过网络发送出去的场景，并且这个过程中你不需要对这些数据进行处理，那一定要使用这个零拷贝的方法，可以有效地提升性能。

- 消息队列如何做到高可用？
	- Rabbit 的单机模式、普通集群模式 (多机器消费一台机器的 queue)、镜像模式 (每台机器同步 queue)
	- Kafka 的模式：一个节点是一个 broker，一个 topic 划分成多个 partion 同步到不同的 broker 上，形成 replica 副本。Replica 选举 leader，读写都与 leader 进行。当消息成功写到所有 replica 副本，消息才可被读到。
- 消息的有序性如何保证？
- 如何设计一个 MQ 系统？
	- 伸缩性方面：可快速扩容，如 Kafka 的 broker -> topic -> partition 的模式
	- 持久化方面：数据需要写入磁盘；生产者与消费者的消息确认机制。
	- 可用性方面：部分节点宕机可快速切换与恢复