#知识大纲 #Redis

# Redis 大纲

![](https://varg-my-images.oss-cn-beijing.aliyuncs.com/img/20220517160132.png)

![](https://varg-my-images.oss-cn-beijing.aliyuncs.com/img/20220517160149.png)

# 使用篇

##  Redis 的使用场景

- 缓存
- 计数相关：计数器/排行榜/浏览量/播放量等
- 交并集操作：共同好友，朋友圈点赞
- 简单消息队列：发布订阅
- Session 服务器

##  Redis 支持的数据结构

- String
- List
- Set
- Sorted Set
- Hash
- Bitmaps
- Hyperloglogs
- Geospatial

##  Redis 实现消息队列

1. Rpush 生产消息，lpop 消费消息，没有消息时 sleep 或者使用 blpop
2. 消息支持多次消费，使用 pub / sub 模式可以达到 1: N 的消息队列
3. Pub / sub 模式的缺点：消费者下线的情况下，生产的消息会丢失
4. 延时队列的实现：基于 SortedSet，以时间戳为 score，消息内容作为 key 来生产消息。调用 zrangebyscore 来获取 N 秒前的数据。

##  Redis 实现分布式锁

- 使用 set/del 添加和释放锁。可带生效时间设定。
- 删除锁时判断线程 ID 是否是自己，防止误删除。
- 重入性使用 state 值来判断。
- 判断锁释放可以通过轮询或者 Redis 的发布订阅机制实现。

##  BigKey 有什么影响

- 网络阻塞，传输耗时长
- 超时阻塞，操作耗时长
- 内存占用高，空间分配不平衡

##  如何查询固定前缀大 key

- Keys 命令。会阻塞线程，查询事件复杂度是 o (n)，且查询结果是全量，不支持分页。
- Scan 命令。不会阻塞线程，但有可能查出重复数据。不保证能得到查询期间被修改的元素。

##  Redis 阻塞可能原因

- 服务器 CPU 负载过高
- 持久化过程占用资源过多
- API 使用不合理，如大 key 查询或 keys 扫描

##  缓存问题

- 缓存雪崩
	- 原因：由于大批量的缓存突然失效导致请求都打到了数据库上
	- 措施
		- 缓存失效时间分开，设置随机失效时间
		- 控制数据库写入操作，只允许一个线程写入
- 缓存穿透
	- 原因：查询缓存中没有的数据，请求打到了数据库
	- 措施
		- 使用布隆过滤器拦截
		- 缓存空的数据，并设置过期时间
- 缓存预热
	- 原理：自动将热点数据加载到缓存中
- 缓存更新
	- Cache-Aside 旁路缓存模式
		- 做法：
			- 读请求
				1. 先查询缓存
				2. 缓存中有直接返回
				3. 缓存中没有查询数据库更新缓存
			- 写请求
				1. 先更新数据库
				2. 然后删除缓存
		- 选择原因
			- 为何不先删除缓存后更新数据库？
				- 若先删除缓存，在缓存删除期间产生读请求，可能会将未更新的数据查询到缓存中导致缓存脏数据。
			- 若选择先删除缓存后更新数据库，如何解决一致性问题？
				- 采用延时双删，更新数据库后延时一段时间再次删除缓存，总共删除两次。这种做法不但需要两次删除而且有延迟，所以不推荐使用。
			- 为何是删除缓存而不是更新缓存？
				- 若产生两个并发的写请求，因为各种原因导致先来请求缓存更新操作晚于后来的请求，同样会导致缓存脏数据。
			- Cache-Aside 存在数据不一致的可能吗？
				- 存在，若缓存失效期间同时产生写请求与读请求，且读请求的缓存更新操作晚于写请求的缓存删除操作，这个时候也会出现数据不一致问题。这种情况要求缓存失效且读写同时触发，条件比较复杂。
				- 另一种情况是读请求先读到了缓存，写请求更新了数据。这个时候缓存与数据库数据不一致，也是一种一致性问题。若是业务对此要求严格一致，可采取加锁方式解决。
		- Cache-Aside 的异常补偿机制
			- 当删除缓存时存在缓存删除失败的问题，需要作出补偿策略。
			- 删除重试机制，同步删除重试影响性能，因此可以使用异步重试删除，如使用 MQ。但这样引入了 MQ 中间件，以及删除失败后但逻辑需要业务代码但 trigger 触发。
			- 监听 binlog 日志，解析 binlog 日志来处理缓存删除失败的问题。注意这里优先选择监听从数据库的 binlog 日志，防止主节点事务还未完成就过早的删除了缓存。
			- 采用云服务商提供的 DTS (数据传输) 服务，DTS 服务适配了常见的数据源与数据操作场景，解决了如 binlog 日志回收，主备切换场景下的高可用问题。
		- 适用点
			- 缓存数据计算逻辑复杂
			- 数据一致性要求高
			- 不存在大key或热点数据
	- Read-Through 读穿透模式
		- 流程和 Cache-Aside 模式相似，不同点在于 Read-Through 多了访问控制层，读请求只和访问控制层交换，缓存能否命中与读请求无关。
	- Write-Through 直写模式
		- 同样提供了访问控制层来进行更高程度的封装。不同于 Cache-Aside 模式的是 Write-Through 不是删除缓存而是更新缓存。该模式适合写操作多且对一致性要求高的场景。
	- Write-Behind 异步回写模式
		- 写请求只更新缓存不更新数据库，数据库在合适的时机异步批量更新。
		- 这种模式写延迟低，吞吐性好，但一致性弱，需要缓存做好高可用，适合于大量的写请求场景。如秒杀，MQ 的消息存储机制等。
	- Write-Around
		- 写请求不更新缓存，缓存设定失效时间，由失效时间自动更新。这种模式适用于一致性要求不高的业务场景。
- 缓存降级
	- 原因：缓存失效或缓存服务器挂掉的情况下不去访问数据库直接返回内存数据或默认数据。以此减少降级对业务对影响操作。

# 原理篇


##  Redis 效率高的原因

- C 语言实现，效率高。
- 纯内存操作。
- 基于非阻塞式的 IO 复用模型。
	- 基于 select/epoll 的事件回调机制，使 Redis 可以在网络 IO 阻塞时处理其他事情。
	- 由操作系统内核与客户端建立连接，Redis 监听这些连接的事件进行处理。
	- 注意这里时网络 IO 操作非阻塞的，对于 Redis 的 server 层来说，如果阻塞的话则会影响后面的所有命令。比如 bigkey 操作，复杂命令的执行，缓存淘汰和刷盘机制等。
- 单线程避免上下文切换，各种锁操作。
	- Redis 的瓶颈往往在于内存和网络带宽，不在 CPU。
	- 单线程避免调度切换开销。
- 丰富的数据结构，对数据存储做了优化，如亚索表，跳表。

##  文件事件模型

- 处理器结构
	- 多个 Socket
	- IO 多路复用程序
	- 文件事件分派器
	- 事件处理器
		- 连接应答处理器
		- 命令请求处理器
		- 命令回复处理器
- 处理器流程
	1. 客户端 Socket 与 Redis 的 Server Socket 请求建立连接
	2. Server Socket 产生 AE_READABLE 事件，事件压入队列中
	3. 文件事件分派器从队列中获取事件，交给连接处理器
	4. 连接处理器建立通信，将 AE_READABLE 事件与命令处理器关联
	5. 客户端发起操作命令，产生 AE_READABLE 事件压入队列。事件分派器将事件交给命令处理器。
	6. 命令处理器处理事件，然后将 socket 的 AE_WRITABLE 事件与回复处理器关联。
	7. 客户端准备好接收结果时，产生 AE_WRITABLE 事件压入队列，命令回复器回复结果。
	8. 最后操作完成，解除命令回复器与 AE_WRITABLE 事件的关联。

##  Redis 的主从同步

### 主从同步的过程

![](https://varg-my-images.oss-cn-beijing.aliyuncs.com/img/20220517231216.png)

主从同步用于备份主库的数据，从库通过与主库建立连接而不断获取到主库到数据。建立连接的步骤如下：
1. 从库使用 replicaof/slaveof (5.0 之前) 来开始主库建立连接。
2. 从库发送 psync 命令给主库建立连接，首次建立连接 runId 为 -1，offset 为 -1。runId 为机器 ID，offset 为复制进度，首次 -1 表示从头开始。
3. 主库通过 FULLRESYNC 响应命令带上两个参数：主库 runID 和主库目前的复制进度 offset，返回给从库。
4. 主库执行 bgsave 命令得到 RDB 文件给从库。从库接收到文件后清空当前数据，然后解析 RDB 恢复数据。使用RDB文件有以下几点原因：
	- RDB 文件是压缩过的二进制文件，文件内容小。对于网络传输快。
	- RDB 文件直接使用二进制协议解析还原数据，避免 AOF 文件的命令重复执行。
5. 对于生成 RDB 文件期间和从库解析 RDB 文件期间产生到数据操作命令，记录到了 replication buffer 中，待后续从库解析完后再根据这些命令补充数据。
6. 首次备份完毕后主从之间通过长连接维护通信，主库将每次改动都推送到从库。

### 主从同步的重连

![](https://varg-my-images.oss-cn-beijing.aliyuncs.com/img/20220517234150.png)

主从连接建立完毕以后就可以正常同步数据了，但是当主从之间因为某些原因断开重新建立连接后，双方数据怎么继续同步呢？

对于主库，在每次收到写入操作后，会将命令存入到 `repl_backlog_buffer` 环形缓冲区。主从之间的通信，会有一个 `replication buffer`。`repl_backlog_buffer` 用于记录主库的写入命令，对于主库来说只有一个。而 `replication buffer` 是对每一个从库都有的，这用于主从之间发送缓冲数据使用。这两者之间更为详细的对比如下：
- `repl_backlog_buffer` 是为了从库断开之后，如何找到主从差异数据而设计的环形缓冲区，从而避免全量同步带来的性能开销。各个从节点的 offset 偏移量都是相对该缓冲区而言的。若一个从库都没有，那么这个缓冲区存在就没有意义了，此时会被释放。
- `replication buffer` 是为了主从之间数据通信**缓冲**所使用的，就像 Mysql 中的 net_buffer。这个 buffer 是针对每一个从库都会有一个的。不管是全量同步还是增量同步，都会使用到这个缓冲区。
- 如果主从在传播命令时，因为某些原因从库处理得非常慢，那么主库上的这个 `replication buffer` 就会持续增长，消耗大量的内存资源，甚至 OOM。所以 Redis 提供了 `client-output-buffer-limit` 参数限制这个 buffer 的大小，如果超过限制，主库会强制断开这个 client 的连接，也就是说从库处理慢导致主库内存 buffer 的积压达到限制后，主库会强制断开从库的连接，此时主从复制会中断，中断后如果从库再次发起复制请求，那么此时可能会导致恶性循环，引发复制风暴，这种情况需要格外注意。

对于缓冲区 `repl_backlog_buffer`，主库使用 `master_repl_offset` 来记录写入的位置。从库使用 `slave_repl_offset` 记录自己从主库读取数据的位置。这样在主从之间数据通信的时候，只需要将两个 offset 之间的数据进行同步即可。

对于主从重新建立连接后，有两种情况：
1. 主库的 `master_repl_offset` 还未追赶上从库的 `slave_repl_offset`，这时只要发送 offset 之间的数据即可。
2. 而如果主库的 `master_repl_offset` 已经追赶上从库的 `slave_repl_offset`，那么将会进行数据的覆盖。数据覆盖后从库就不能通过 offset 进行数据同步了，此时只能进行全量数据同步。
3. 因此需要特别留意 `repl_backlog_size` 这个配置参数。如果它配置得过小，在增量复制阶段，可能会导致从库的复制进度赶不上主库，进而导致从库重新进行全量复制。

对于 `repl_backlog_buffer` 的大小，可以通过 `repl_backlog_size` 参数进行控制。这个参数和所需的缓冲空间大小有关。缓冲空间的计算公式是：缓冲空间大小 = 主库写入命令速度 * 操作大小 - 主从库间网络传输命令速度 * 操作大小。在实际应用中，考虑到可能存在一些突发的请求压力，我们通常需要把这个缓冲空间扩大一倍，即 repl_backlog_size = 缓冲空间大小 * 2，这也就是 repl_backlog_size 的最终值。

##  Pipline

- 将多次 IO 压缩成一次，但是要求管道中的指令没有因果关系。
- 使用 pipline 实现请求/响应的功能。客户端未读取服务端响应时服务端可处理新的请求。客户端发送多个命令时只需等待服务端最终结果。

##  Redis 的持久化方式

### AOF (Append-only-file)

#### AOF 原理

- 原理：将所有命令以 Redis 命令请求协议存储，保存为 AOF 文件。命令保存时机有以下配置：
	- Always：同步写回。每个写命令执行完，立马同步地将日志写回磁盘。崩溃时会丢失一次事件循环的命令。在同步时下一次事件循环才会把上一次的事件产生的缓冲 fsync 同步到磁盘中。
	- Everysec：每秒写回。每个写命令执行完，只是先把日志写到 AOF 文件的内存缓冲区，每隔一秒把缓冲区中的内容写入磁盘。崩溃时会丢失一秒内的命令。
	- No：操作系统控制的写回。每个写命令执行完，只是先把日志写到 AOF 文件的内存缓冲区，由操作系统决定何时将缓冲区内容写回磁盘。崩溃时会丢失不可控数据的命令。

- 优点
	- 数据安全，一次操作就可以备份一次
	- 通过 append 模式，即使中途宕机也可以回复数据
	- 有 rewrite 模式，当 aof 文件过大时可以进行命令合并
- 缺点
	- AOF 文件偏大，恢复慢
	- 数据集大时，比 RDB 启动效率低

#### AOF重写

![](https://varg-my-images.oss-cn-beijing.aliyuncs.com/img/20220517181251.png)

当操作命令积累时，AOF 文件会变大。AOF 重写支持已当前数据库的所有数据，对其生成每一条 set 命令，从而产生一个全新的 AOF 文件。重写机制具有“多变一”功能，该 AOF 文件理论上会比原始文件小许多，这个操作称为 AOF 重写。

每次 AOF 重写时，Redis 会先执行一个内存拷贝，用于重写。然后，使用两个日志保证在重写过程中，新写入的数据不会丢失。而且，因为 Redis 采用额外的线程进行数据重写，所以，这个过程并不会阻塞主线程。

但是 AOF 重写存在阻塞主线程的风险：
1. fork 这个瞬间一定是会阻塞主线程的，fork 采用操作系统提供的写实复制 (Copy On Write) 机制，就是为了避免一次性拷贝大量内存数据给子进程造成的长时间阻塞问题。但 fork 子进程需要拷贝进程必要的数据结构，其中有一项就是拷贝内存页表（虚拟内存和物理内存的映射索引表），这个拷贝过程会消耗大量 CPU 资源，拷贝完成之前整个进程是会阻塞的，阻塞时间取决于整个实例的内存大小，实例越大，内存页表越大，fork 阻塞时间越久。
2. 拷贝内存页表完成后，子进程与父进程指向相同的内存地址空间，也就是说此时虽然产生了子进程，但是并没有申请与父进程相同的内存大小。“写实复制”是在写发生时，才真正拷贝内存真正的数据，这个过程中，父进程也可能会产生阻塞的风险。
	1. fork 出的子进程指向与父进程相同的内存地址空间，此时子进程就可以执行 AOF 重写，把内存中的所有数据写入到 AOF 文件中。但是此时父进程依旧是会有流量写入的，如果父进程操作的是一个已经存在的 key，那么这个时候父进程就会真正拷贝这个 key 对应的内存数据，申请新的内存空间。这样逐渐地，父子进程内存数据开始分离，父子进程逐渐拥有各自独立的内存空间。
	2. 因为内存分配是以页为单位进行分配的，默认4k。如果父进程此时操作的是一个bigkey，重新申请大块内存耗时会变长，可能会产阻塞风险。另外，如果操作系统开启了内存大页机制(Huge Page，页面大小2M)，那么父进程申请内存时阻塞的概率将会大大提高，所以在**Redis机器上需要关闭Huge Page机制**。Redis每次fork生成RDB或AOF重写完成后，都可以在Redis log中看到父进程重新申请了多大的内存空间。

AOF 重写的配置：
- `auto-aof-rewrite-min-size 64mb` 配置 AOF 文件运行时最大容量。
- `auto-aof-rewrite-percentage 100` 配置 AOF 文件运行时本次 AOF 文件与上一次 AOF 文件体积增量比。
- 在 aof 文件体量超过 `auto-aof-rewrite-min-size`，且比上次重写后的体量增加了 `auto-aof-rewrite-min-size` 时自动触发重写。
- 可以手动发送 `bgrewriteaof` 指令触发一次重写。

Redis4.0 以后，Redis 的 AOF 重写的时候就直接把 RDB 的内容写到 AOF 文件开头，将增量的以指令的方式 Append 到 AOF，这样做的好处是可以结合 RDB 和 AOF 的优点, 快速加载同时避免丢失过多的数据。缺点是 AOF 里面的 RDB 部分就是压缩格式不再是 AOF 格式，可读性较差。

### RDB (Redis DataBase Back File)

### RDB 原理

![](https://static001.geekbang.org/resource/image/a2/58/a2e5a3571e200cb771ed8a1cd14d5558.jpg)

原理：定期生成所有数据的快照，依赖快照恢复。采用写时复制技术实现，不会阻塞 Redis 读写操作。

- 优点
	- 只有一个 `dump.rdb` 文件，方便持久化。
	- 单个文件方便存储。
	- 性能最大化，fork 子线程备份，主线程不阻塞，IO 最大化.
	- 数据集大时，比 AOF 启动效率高。
- 缺点
	- 间隔时间太长，容易丢失数据。间隔事件太短，对磁盘和 CPU 的抢占率高，容易阻塞主线程。
	- 在写请求高于读请求，且写请求分散在大量数据的情况下，RDB 进行的时候会发生以下风险：
		- 内存资源风险，大量写请求会导致主线程进行内存复制与分离，这是内存使用率会上升。当到达机器容量时，若未配置 swap 策略则会出现 OOM 现象，若配置了会导致内存热点数据与磁盘的交换，导致性能下降。
		- CPU 资源风险：在 CPU 核心少时，主线程已占用了一个线程。fork 的子线程会再占用一个且消耗资源较高。同时还存在其他刷盘，异步关闭文件符这些操作的线程，以及系统内其他的线程。这些线程的争用导致性能下降。

### AOF 与 RDB 混合模式

Redis4.0 引入了混合模式，支持 RDB 与 AOF 同时使用。新的 AOF 文件前半段是 RDB，后半段是增量的 AOF。采用混合模式既可以利用 RDB 模式备份文件小和全的特性，又可以利用 AOF 一致性高的特性。

![](https://varg-my-images.oss-cn-beijing.aliyuncs.com/img/20220517194638.png)

##  Redis 为什么是单线程的

- Redis中的多线程
	- 在 Redis4.0 中引入了多线程处理异步任务
	- 在 Redis6.0 中对网络模型实现了多线程 IO，用于处理网络数据对读写和协议解析。主线程将可读 Socket 分发给 IO 线程组进行并行请求解析，解析完毕的命令执行还是单线程的，执行结果交给 IO 线程组写回 Socket 是并行的。即将与 Socket 相关的读写操作变为并行执行的，以此减轻网络 IO 的负担。但是命令执行还是由主线程执行的，仍是单线程，且是线程安全的。

##  Redis 集群模式

- Sential
- Cluster
	- 所有节点互相连接
	- 集群消息通过集群总线通信
	- 节点与节点通过二进制协议通信
	- 客户端与集群节点正常文本协议通信
	- 集群节点不代理查询
	- 数据按 Slot 存储在多个 Redis 实例上。Redis 集群内置 16384 个哈希槽，将 key 按 CRC16 算法计算后对 16484 取余。
	- 集群节点宕机时自动故障转移
	- 可以平滑扩/缩容
- 集群优化策略
	- Master 不做持久化工作
	- 数据交给 Slave 开启持久化备份
	- Master 和 Slave 保持在同一个局域网
	- 避免在压力大大主库上增加从库
	- 主从复制避免图结构，使用单项链表保持节点切换简单

##  Redis 的内存淘汰策略

- Volatile-lru：从已设置过期时间的数据集中挑选最近最少使用的数据
- Volatile-ttl：从已设置过期时间的数据集中挑选即将过期的数据
- Volatile-random：从已设置过期时间的数据集中任意挑选数据
- Allkeys-lru：从所有键中挑选最近最少使用的数据
- Allkeys-random：从所有键中中任意挑选数据
- No-enviction：禁止淘汰数据。新写入操作会报错。
- 基于 volatile 策略时若没有键设置了超时时间，那么表现效果和 allkeys 效果一致。

##  Redis 的过期策略

- 定时删除策略：设定定时器，时间到了就删。此种方式资源消耗大。
- 定期删除策略：每隔一定时间扫描删除。不是扫描所有 key，而是随机抽一部分。
- 惰性删除：操作 key 时如果发现过期了就删除。

##  Redis 的事务

- Redis事务的特性
	- 事务失败时不支持回滚
	- 一个事务中出现运行错误，其余的命令会继续执行
- Redis 事务的使用
	- MULTI 开启一个事务
	- EXEC 执行一个事务
	- DISCARD 取消一个事务
	- WATCH 提供 Check And Set 的能力，可以监控一个或多个键。一旦某个键被修改/删除，之后的事务就不会执行。

##  Redis 的 hash 冲突与 hash 扩容

- Hash 冲突：使用链表保存冲突的数据
- Hash 扩容：渐进式 hash，从第一个索引开始一点一点的转移数据

##  Redis 分区

- 方案
	- 代理分区：将请求发送给代理，让代理决定对哪个节点读写。如 Twemporxy
	- 客户端分区：由客户端根据一定规则将数据分散到不同节点上
	- 查询路由：客户端随机请求一个 Redis 实例，Redis 转发给正确的 Redis 节点。
- 缺点
	- 涉及多 key 的操作不能很好的支持，如无法直接对分布到不同节点的 key 做交并集计算
	- 同时操作多个 key，无法使用事务
	- 分区的粒度是 key，无法使用一个非常长的排序 key 存储一个数据集
	- 数据处理会变得复杂，如备份时需要收集多个节点的数据
	- 需要处理动态缩扩容的问题
