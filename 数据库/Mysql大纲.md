#知识大纲 #数据库 

# Mysql大纲

![](https://varg-my-images.oss-cn-beijing.aliyuncs.com/img/20220505002334.png)


## 数据库中的建

1. 超键：唯一标记元祖的属性集
2. 候选键：超键中不包含多余的属性
3. 主键：候选键选择一个作为主键
4. 外键
5. 主属性
6. 非主属性

## 数据库范式

1. 1NF：列不可拆分
2. BCNF：任意字段不能与候选键存在传递依赖。消除主属性对键对传递函数依赖。
3. 3NF：非主属性不能与候选键存在传递依赖。消除非主属性对键的传递函数依赖。
4. 2NF：非主属性完全依赖候选键，不能部分依赖，否则造成数据冗余与耦合。消除非主属性对键的部分函数依赖。

## Mysql 常用引擎

- MyISAM，全表锁，无事务、外键，非聚集索引。
	- Innodb，行级锁，有提交回滚等事务特性。支持自增列，外键，并发强。占用空间是 MyISAM 的 2.5 倍。主键为聚集索引。
	- Memory，表锁
	- Merge，MyISAM 表的组合

## 数据库事务 ACID


## Mysql 索引

- 聚集索引，Mysql 会自动将主键索引放到其他索引的后面
- 覆盖索引：在联合索引上就有待查询待全部字段无需回表。
	- 索引下推：当索引上条件能判断时就不会回表判断。
- 联合索引
	- 联合索引的最左匹配原则，从左边开始的字段能走上索引，遇到范围查询 (>,<, between, like 停止)
	- 若 (a, b) 为联合索引，查询条件 b = xx and a = xx 也能走上索引，引擎会自动优化。
- 前缀索引，Mysql 支持指定字符串或二进制的前 n 位构建索引。当前缀区分度不高时，可以考虑使用后缀，即 reverse (field) 代替。或者新加一个字段，这个字段调用 crc32 () 这样的 hash 函数进行拓展字段建立。需要注意的时候当使用了前缀索引后就无法使用到覆盖索引这个特性了，因为数据库就无法判断该索引上是否包含完整的值。
- 唯一索引
- 普通索引：如果没有特别要求，索引尽量选择普通索引。普通索引可以使用 **ChangeBuffer 进行缓冲**，从而改善性能。
- 索引重建
	- 目的：索引可能因为删除，页分裂等原因造成数据空洞。重建索引会创建新的索引，时页面利用率最高。索引更紧凑，更省空间。
	- 重建非主键索引：`drop index`
	- 重建主键索引：避免使用 `drop primary key`，因为这个会先删除旧的主键索引，然后 innodb 又自己使用了一个临时主键索引，最后又自己指定了主键索引。导致主键重构两次。用 `alter table T engine=InnoDB` 代替。
		- `alter table T engine=InnoDB` 是一个重建表的操作，会基于原来的表 inplcae 一个新的表出来。过程是 Online 的，在语句执行的时候会先回去 MDL 的写锁，之后会退化成读锁，避免阻塞增删改查。
		- `analyze table t` 是一个重建统计表索引的操作。
		- `optimize table t` 等于 recreate + analyze。
- 索引评估：数据库评估索引的扫描行数是基于采样分析的，可能不准确。可以使用 `analyze table t` 来使数据库对索引情况进行重新评估，从而使扫描行数变准确。
- 自适应哈希索引

## SQL 优化的途径

- 不要使用 select *
- 减少子查询，用关联查询代替。子查询会生成临时表，关联查询不会。
- 当子查询表大时，用 exists。子查询表小时，用 in。另无论哪个表大，not in 会扫全表，not exists 可以使用到索引。
- Or 的查询看情况是否可以使用 union 或 union all 代替。
- 减少 != 条件的使用，否则会全表扫描。
- 避免在 where 条件中进行 null 值判断，否则可能会全表扫描。
- 避免在 where 条件中对字段进行函数计算

## Truncate、drop、delete 区别

- Truncate 和 drop 不走事务，不触发trigger。
- Truncate 和 drop 是 ddl 语句。Delete 是 dml 语句。

## 并发带来的问题

- 脏读
- 丢失修改
- 不可重复读
- 幻读

## 数据库隔离级别

- Read-UnCommitter
- Read-Committed
- Repeatable-Read
	在此隔离级别下，存在 MVCC 模式。对于每一个操作，都会产生一个 undo 日志，undo 日志会和事务产生关联。因此如果一个事务非常长的话那么就会占用很大的 undo 日志空间。Undo 日志删除的条件是没有比这个日志更早的 read-view，所以要尽量避免长事务。
- Serializable

## 大表优化的思路

- 限定查询范围
- 读写分离
- 垂直分区，拆列
- 水平分区，拆行
- 分库分表

##  数据库分片两种常见方案

- 客户端代理，如 Sharding-Jdbc。封装在 jar 包中，通过修改或封装 jdbc 实现。
- Mycat，中间件代理。处于应用和数据层之间。

## 分库分表后 id 解决方案

- UUID
- 数据库自增 ID。设置不同步长与 ID 生成策略。
- 利用 Redis 中间件生成。
- SnowFlake 算法。
- 其他分布式 ID 生成系统，如美团的 Leaf。

## SQL 的执行流程

1. 取得数据库连接器
2. 查询缓存，Mysql8.0 中已移除
3. SQL 词法分析
4. 优化器优化，如使用哪个索引，join 连接顺序
5. 执行器执行

## SQL 语句的执行顺序

1. From 表做笛卡尔积
2. 执行 On 过滤
3. 添加外部行，这里在左连接或右连接才会有
4. 执行 Where 过滤
5. 执行 Group By 分组
6. 执行 Having 过滤
7. 执行 Select 列选择
8. 执行 Distinct 过滤数据 (这里会生成临时表，在过滤列上加唯一索引)
9. 执行 Order By 语句
	- Order By 排序算法有两种，全字段排序与 rowId 排序
		- 全字段排序，使用时会根据条件筛选出所有满足条件的数据，然后对数据按给定的字段排序。排序过程中每条数据是全字段，排序完即可返回数据
		- RowId 排序，排序时若一条数据过长，超过 `max_length_for_sort_data` 时，就会采用 rowId 排序。此时排序的数据就只有排序关键字与主键 ID。排序完毕后根据主键 ID 回表再次查出数据。这里回表时就可能涉及到磁盘的读写了。
		- 如果满足了索引覆盖的条件的话，那么就不会有排序动作了。从 B+树取出来的数据本身就是有序的。
	- 排序过程
		- 排序时会优先在内存中进行快速排序，当内存数据不足时会使用磁盘进行辅助排序。
		- 使用磁盘辅助排序时，将数据分割成小文件，每个小文件使用归并排序，排序完毕后进行合并返回。
	- Order by rand () 的实现
		- 首先会在内存中新建临时表，临时表长度不够的话会在磁盘中建。当超过 `internal_tmp_disk_storage_engine` 值时就会生成磁盘的临时表。临时表的内容为排序字段与为每条数据生成的一个随机数 r。
		- 在生成的临时表中使用随机数 r 进行排序。
			- 对生成的临时表排序，会优先使用 rowId 排序算法。因为这样可以减少数据量。
			- 对于排序过程，若是指定的 limit 小的话，会使用优先队列排序。如 limit3 则只会维护三个最大值/最小值。避免全排序。
			- 若是 limit 大的话，超过排序的 `sort_buffer_size` 时就会使用归并排序了。
		- 排序完毕按 limit 取数。
10. 执行 Limit 语句

## Varchar (11) 与 Int (11) 区别

Varchar 指定存储长度，int 指定显示长度。注意 Varchar 的 OrderBy 排序时使用 fixed_length 计算 col 长度。

## MVCC 的实现原理

- Undo 日志：记录数据的历史变化情况，通过 undo 日志可以追溯到以前的数据。
- ReadView
	- Mysql 的数据隐藏列中包含以下几个字段：roll_pointer，指向 undo 日志。Trx_id，指向这条日志产生的源事务 ID。Row_id，当没有主键是隐藏的主键 ID。
	- 在执行增/删/改的时候，每操作一次就会产生一条 undo 日志。Undo 日志包含上述的字段内容，根据 roll_pointer 就可以产生一条版本链。
	- 基于版本链的情况下，当查询操作产生的时候就会构造 ReadView 视图，从版本链中获取数据。生成 ReadView 视图时会包含以下内容：
		- M_ids：生成 ReadView 视图时活跃的事务 ID 列表。
		- Creator_trx_id：生成 ReadView 视图的事务 ID，即当前事务 ID。
		- Max_trx_id：生成 ReadView 视图时应该分配给下一个事务的 ID。
		- Min_trx_id：生成 ReadView 视图时活跃事务列表中最小的事务 ID。
	- MVCC 的规则如下：
		- 若当前版本链上数据的事务 ID 等于 Creator_trx_id，表示数据由当前事务产生，可读。
		- 若当前版本链上数据的事务 ID 大于 Max_trx_id，表示数据是视图创建之后产生的，不可读。往版本链往前找。
		- 若当前版本链上数据的事务 ID 小于 Min_trx_id，表示数据是视图创建之前产生的，可读。
		- 若当前版本链上数据的事务 ID 在 M_ids 列表中
			- 事务未提交：不可读。
			- 事务已提交
				- RC 级别下，数据可读。
				- RR 级别下，需要保持可重复读的特性，因此不可读。有一种特殊情况，若当前事务先对其进行更新操作，更新会触发当前读获取到最新数据更新。更新完之后该数据事务 ID 会变成当前事务 ID，当前事务就可读到了。

## Mysql 的锁

- 锁分类
	- 按范围分类
		- 数据库锁：对数据库加锁。
			- `Flush tables with read lock (FTWRL)`，使数据库处于只读状态
			- 如果只是备份的话可以使用 `mysqldump–single-transaction` 来保证隔离型的读。注意使用这个语句需要所有数据表都是 InnoDB 引擎的。
			- 使用 `set global readonly=true` 的方式。这种方式有两个问题，其一是这个值通常用来处理一些其他情况，如是主库还是从库。另一个是修改 global 影响大，FTWRL 中断后自动释放锁，而 readonly 设置确不会。
		- 表锁
			- `lock tables ... read/write`，主动开启与释放锁。线程 A 中执行 `lock tables t1 read, t2 write;` 这个语句，则其他线程写 t1、读写 t2 的语句都会被阻塞。同时，线程 A 在执行 unlock tables 之前，也只能执行读 t1、读写 t2 的操作。连写 t1 都不允许，自然也不能访问其他表。
			- MDL (metadata lock)，是 Mysql5.5 版本增加的。会在操作一个表的时候自动加读/写锁。需要注意的是，在修改表结构的时候，**若前面有事务没释放锁，则修改表结构操作会阻塞。表结构操作阻塞后后续所有的请求都会阻塞。**
			- OnlieDDL执行过程
				1. 拿 MDL 写锁
				2. 降级成 MDL 读锁
				3. 真正做 DDL，这里不会阻塞读写操作
				4. 升级成 MDL 写锁
				5. 释放MDL锁
		- 行锁
		- 共享锁
		- 排他锁
	- 按锁机制分类
		- 悲观锁
		- 乐观锁
	- 按锁实现分类
		- S 锁
		- X 锁
		- IS 锁
		- IX 锁
		- Gap 锁
		- Next-key 锁
- 锁升级
	- 当行锁无法匹配数据时，会升级到表锁
	- 当索引记录超过整表 1/2 时，会走到全表查询。行锁变表锁。
- 死锁
- 死锁避免
	- 设定超时时间
	- 设定资源访问顺序
	- 避免事务交叉
	- 使用低隔离级别
	- 主动死锁检测，在尝试获取锁的时候进行死锁检测。当发现自己的操作可能发生阻塞时，就主动回滚事务让其他事务执行。`innodb_deadlock_detect` 默认就是开启的。这里检测的时候不会扫描所有事务，只会扫描和当前线程操作资源相关的事务。
- 死锁解除
	- 当线程持有锁时间超过 `innodb_lock_wait_timeout` 时，就主动放弃锁回滚事务。这个值默认是 50s。
- 两段锁协议
	- 在 InnoDB 事务中，行锁是需要的时候加上去的，但并不是不需要了就立刻释放，而是等到事务结束才释放。这就是两阶段锁协议。
	- 如果你的事务需要锁多个行，那么尽可能把造成锁冲突的，影响并发的语句往后放。
- 加锁过程
	- RC 级别
		- 主键索引
			- 等值查询
				加 X/S 锁，若是更新操作，会为涉及数据字段的二级索引加锁。若是删除操作，会对涉及数据的所有二级索引加锁。
			- 范围查询
				从满足条件的数据开始加锁，加锁规则与等值查询相同。当下一条数据不满足条件时，会先加锁再释放锁(5.7版本实验结果)。所以要注意锁争用问题。
		- 普通索引
			- 等值查询
				加 X/S 锁，若是不满足索引下推条件需要回表，还会对主键索引进行加锁。这里不会出现对下一个不满足条件对数据加锁的情况。
			- 范围查询
				加锁同等值查询。若是查询语句，当下一个数据不满足条件时，会将二级索引加锁，但是不会释放锁。若是更新语句，则会先对二级索引和主键索引加锁，然后发现不满足条件又释放锁。(5.7 版本实验结果)。更新操作无法使用索引下推特性，因此才会对二级索引和主键索引都加锁。
		- 无索引
			存储引擎扫描一行就对该行加 S/X 锁，返回 Server 层发现不满足条件后又释放锁。若是更新操作，还会对涉及到对二级索引加锁。
	- RR 级别
		- 加锁规则
			- 原则 1：加锁的基本单位是 next-key lock。Next-key lock 是前开后闭区间。Next-key 锁实际上是间隙锁+行锁组成的。
			- 原则 2：查找过程中访问到的对象才会加锁。
			- 优化 1：索引上的等值查询，给主键索引加锁的时候，next-key lock 退化为行锁。
			- 优化 2：索引上的等值查询，向右遍历时且最后一个值不满足等值条件的时候，next-key lock 退化为间隙锁。
			- 一个 bug：唯一索引上的范围查询会访问到不满足条件的第一个值为止。在 8.0.18 后已修复。
			- 利用索引的有序性，若一个数据的索引不在被加锁的区间内就不会受到影响。
		- 加锁示例
			- 数据准备
				准备表 t (id, c, d)，其中 id 为主键，c 为普通索引，d 无索引。数据准备为 (0, 0)，(5, 5)，(10, 10)，(15, 15)，(20, 20)，(25, 25)
			- `update t set d = d+1 where id = 7;`
				会对主键索引 (5, 10) 区间加间隙锁。
			- `select id from t where c = 5 lock in share mode;`
				会对二级索引 c 加 Next-key 锁 (0, 5]与间隙锁 (5, 10)。由于索引覆盖，所以不会对主键索引加锁。Sql 查询字段若是改为 d，则回表会导致主键索引也被加锁。
			- `select * from t where id>=10 and id<11 for update;`
				会对主键索引行 10 以及 next-key 锁 (10, 15]进行加锁。其实这里发现 15 是不满足条件的，没必要进行加锁。在版本 8.0.19 上已经退化成间隙锁 (10, 15) 了。
			- `select * from t where c>=10 and id<11 for update;`
				这里 c 是普通索引，会对二级索引 c 加 next-key 锁 (5, 10]及 next-key 锁 (10, 15]进行加锁。同时对主键索引 10 加行锁。同 8.0.19 上后一个 next-key 锁会退化成间隙锁 (10, 15)。
				如果 c 是 uniqu 唯一索引的话，也还是 next-key 锁 (5, 10]及 next-key 锁 (10, 15]，前一个锁不会退化成行锁，只有主键索引会。测试版本为 8.0.20。
			- `select * from t where id>10 and id<=15 for update;`
				会对主键索引加 next-key 锁 (10, 15]及 (15, 20]进行加锁。8.0.18 后已优化唯一索引范围查询的加锁方式，只会有 (10, 15]的 next-key 锁。
			- 多增加一条数据 `insert into t values(30,10,30);`
				- `delete from t where c = 10;`
					此时存在两条 c=10 的数据，会对二级索引 c 加 (5: 5, 10: 10]，(10: 10, 10: 30]，(10: 30, 15:15)，同时对主键索引 5，10，30，15 加行锁。
				- `delete from t where c = 10 limit 2;`
					由于多了 limit 条件，因此扫描到两行后就会结束。此时加锁情况为对二级索引 c 加 (5: 5, 10: 10]，(10: 10, 10: 30]，对主键索引 5，10，30 加行锁。所以删除时如果行数确定的话尽量加上 limit 条件，这样可以减少锁的范围。
				- `select * from t where c >= 15 and c <= 20 order by c desc for update;`
					会对二级索引 c 加 (20, 25]，(15, 20]，(10, 15]，(5, 10]next-key 锁，同时对主键索引 10, 15, 25 加行锁。在 8.20 版本二级索引 c (20, 25]已优化为 (20, 25)，且主键索引无 25 的行锁。
					原因是因为这是倒序排序，所以索引会从后往前扫。扫描数据 15 时会发现仍满足条件，因此继续往前扫描一条数据，所以就对 10 也加上了锁。
			- 死锁的例子
				![](https://varg-my-images.oss-cn-beijing.aliyuncs.com/img/20220513130251.png)
				事务 A 加了 (5, 10]和 (10, 15) 的锁，事务 B 加 (5, 10]的锁时失败阻塞，事务 A 再次插入时进入死锁状态。原因是因为 next-key 锁实际上是由间隙锁+行锁组成的。所以 B 加锁时其实是先加 (5, 10) 的间隙锁，成功，后加行锁是阻塞的。而事务 A 再次插入时被事务 B 的间隙锁锁住，因此阻塞进入死锁。

## 一条 SQL 执行慢的原因

- 偶尔慢
	- 数据库在刷新脏页
		- Redo 日志满了
		- 内存满了
		- MySql 正常刷新脏页
		- 正在关机
		- 脏页刷新的快慢和 Myql 的 iops 变量设置与当前脏页比例有关。
	- 获取不到锁
		- 可以通过 `show processlist` 来查看是否有阻塞表锁的线程。
		- 可以通过`select * from t sys. Innodb_lock_waits where locked_table=\`'test'.'t\'\`\G\`来查看锁阻塞情况。
	- 查询是快照读，有事务进行了大量更新操作没提交，产生大量 undo 日志。快照读需要解析这些 undo 日志因此耗时长。
- 一直慢
	- 没正确使用索引
		- 联合索引使用了范围语句导致没用上
		- 使用了函数计算导致没用上。如 month () 这类。当两个表连接是，字段类型不同。如 `t1.a = t2.b`，, t1. A 的编码是 utf-8，, t2. B 的编码是 utf8mb4，此时 t1. A 会发生隐式函数计算 `CONVERT(t1.a USING utf8mb4) = t2.b;` 而导致无法使用索引。
		- 隐式类型转换导致没用上，比如 `.. where c = 1`，若 c 是字符串类型，相当于隐式执行了 `CAST(c AS signed int)` 这个转换。而如果索引是数值类型条件是字符串则不会有这个情况。
	- 索引没建
	- 由于数据库原因导致索引失效。如是否使用临时表，是否排序，估算的索引扫描行数等。

## Count 的区别

- Count 是扫描表中有多少条数据，然后将数据行数求和返回结果的。为什么不缓存一个表的记录数这样一个字段呢？因为每个事务可能查到不同的条数。
- Count 的各个区别
	- Count (\*)，取出一条数据就 + 1，这是 Mysql 官方的优化方式。
	- Count (1)，取出一条数据就 + 1，这是人为操作的优化方式。
	- Count (field)，取出一条数据的 field 字段，若字段不为空，则 +1，否则不加。
	- (0,0),(5,5), (10,7) (10,10)