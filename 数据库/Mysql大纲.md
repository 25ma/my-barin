#知识大纲 #数据库 

# Mysql大纲

![](https://varg-my-images.oss-cn-beijing.aliyuncs.com/img/20220505002334.png)


## 数据库中的键

1. 超键：唯一标记元祖的属性集
2. 候选键：超键中不包含多余的属性
3. 主键：候选键选择一个作为主键
4. 外键
5. 主属性
6. 非主属性

## 数据库范式

1. 1NF：列不可拆分
2. BCNF：任意字段不能与候选键存在传递依赖。消除主属性对键对传递函数依赖。
3. 3NF：非主属性不能与候选键存在传递依赖。消除非主属性对键的传递函数依赖。
4. 2NF：非主属性完全依赖候选键，不能部分依赖，否则造成数据冗余与耦合。消除非主属性对键的部分函数依赖。

## Mysql 常用引擎

- MyISAM，全表锁，无事务、外键，非聚集索引。
	- Innodb，行级锁，有提交回滚等事务特性。支持自增列，外键，并发强。占用空间是 MyISAM 的 2.5 倍。主键为聚集索引。
	- Memory，表锁
	- Merge，MyISAM 表的组合

## 数据库事务 ACID

## Mysql 索引

- 聚集索引，Mysql 会自动将主键索引放到其他索引的后面
- 覆盖索引：在联合索引上就有待查询待全部字段无需回表。
	- 索引下推：当索引上条件能判断时就不会回表判断。
- 联合索引
	- 联合索引的最左匹配原则，从左边开始的字段能走上索引，遇到范围查询 (>,<, between, like 停止)
	- 若 (a, b) 为联合索引，查询条件 b = xx and a = xx 也能走上索引，引擎会自动优化。
- 前缀索引，Mysql 支持指定字符串或二进制的前 n 位构建索引。当前缀区分度不高时，可以考虑使用后缀，即 reverse (field) 代替。或者新加一个字段，这个字段调用 crc32 () 这样的 hash 函数进行拓展字段建立。需要注意的时候当使用了前缀索引后就无法使用到覆盖索引这个特性了，因为数据库就无法判断该索引上是否包含完整的值。
- 唯一索引
- 普通索引：如果没有特别要求，索引尽量选择普通索引。普通索引可以使用 **ChangeBuffer 进行缓冲**，从而改善性能。
- 索引重建
	- 目的：索引可能因为删除，页分裂等原因造成数据空洞。重建索引会创建新的索引，时页面利用率最高。索引更紧凑，更省空间。
	- 重建非主键索引：`drop index`
	- 重建主键索引：避免使用 `drop primary key`，因为这个会先删除旧的主键索引，然后 innodb 又自己使用了一个临时主键索引，最后又自己指定了主键索引。导致主键重构两次。用 `alter table T engine=InnoDB` 代替。
		- `alter table T engine=InnoDB` 是一个重建表的操作，会基于原来的表 inplcae 一个新的表出来。过程是 Online 的，在语句执行的时候会先回去 MDL 的写锁，之后会退化成读锁，避免阻塞增删改查。
		- `analyze table t` 是一个重建统计表索引的操作。
		- `optimize table t` 等于 recreate + analyze。
- 索引评估：数据库评估索引的扫描行数是基于采样分析的，可能不准确。可以使用 `analyze table t` 来使数据库对索引情况进行重新评估，从而使扫描行数变准确。
- 自适应哈希索引

## SQL 优化的途径

- 不要使用 select *
- 减少子查询，用关联查询代替。子查询会生成临时表，关联查询不会。
- 当子查询表大时，用 exists。子查询表小时，用 in。另无论哪个表大，not in 会扫全表，not exists 可以使用到索引。
- Or 的查询看情况是否可以使用 union 或 union all 代替。
- 减少 != 条件的使用，否则会全表扫描。
- 避免在 where 条件中进行 null 值判断，否则可能会全表扫描。
- 避免在 where 条件中对字段进行函数计算

## Truncate、drop、delete 区别

- Truncate 和 drop 不走事务，不触发trigger。
- Truncate 和 drop 是 ddl 语句。Delete 是 dml 语句。

## 并发带来的问题

- 脏读
- 丢失修改
- 不可重复读
- 幻读

## 数据库隔离级别

- Read-UnCommitter
- Read-Committed
- Repeatable-Read
	在此隔离级别下，存在 MVCC 模式。对于每一个操作，都会产生一个 undo 日志，undo 日志会和事务产生关联。因此如果一个事务非常长的话那么就会占用很大的 undo 日志空间。Undo 日志删除的条件是没有比这个日志更早的 read-view，所以要尽量避免长事务。
- Serializable

## 大表优化的思路

- 限定查询范围
- 读写分离
- 垂直分区，拆列
- 水平分区，拆行
- 分库分表

##  数据库分片两种常见方案

- 客户端代理，如 Sharding-Jdbc。封装在 jar 包中，通过修改或封装 jdbc 实现。
- Mycat，中间件代理。处于应用和数据层之间。

## 分库分表后 id 解决方案

- UUID
- 数据库自增 ID。设置不同步长与 ID 生成策略。
- 利用 Redis 中间件生成。
- SnowFlake 算法。
- 其他分布式 ID 生成系统，如美团的 Leaf。

## SQL 的执行流程

1. 取得数据库连接器
2. 查询缓存，Mysql8.0 中已移除
3. SQL 词法分析
4. 优化器优化，如使用哪个索引，join 连接顺序
5. 执行器执行

## SQL 语句的执行顺序

1. From 表做笛卡尔积
2. 执行 On 过滤
3. 添加外部行，这里在左连接或右连接才会有
4. 执行 Where 过滤
5. 执行 Group By 分组
6. 执行 Having 过滤
7. 执行 Select 列选择
8. 执行 Distinct 过滤数据 (这里会生成临时表，在过滤列上加唯一索引)
9. 执行 Order By 语句
	- Order By 排序算法有两种，全字段排序与 rowId 排序
		- 全字段排序，使用时会根据条件筛选出所有满足条件的数据，然后对数据按给定的字段排序。排序过程中每条数据是全字段，排序完即可返回数据
		- RowId 排序，排序时若一条数据过长，超过 `max_length_for_sort_data` 时，就会采用 rowId 排序。此时排序的数据就只有排序关键字与主键 ID。排序完毕后根据主键 ID 回表再次查出数据。这里回表时就可能涉及到磁盘的读写了。
		- 如果满足了索引覆盖的条件的话，那么就不会有排序动作了。从 B+树取出来的数据本身就是有序的。
	- 排序过程
		- 排序时会优先在内存中进行快速排序，当内存数据不足时会使用磁盘进行辅助排序。
		- 使用磁盘辅助排序时，将数据分割成小文件，每个小文件使用归并排序，排序完毕后进行合并返回。
	- Order by rand () 的实现
		- 首先会在内存中新建临时表，临时表长度不够的话会在磁盘中建。当超过 `internal_tmp_disk_storage_engine` 值时就会生成磁盘的临时表。临时表的内容为排序字段与为每条数据生成的一个随机数 r。
		- 在生成的临时表中使用随机数 r 进行排序。
			- 对生成的临时表排序，会优先使用 rowId 排序算法。因为这样可以减少数据量。
			- 对于排序过程，若是指定的 limit 小的话，会使用优先队列排序。如 limit3 则只会维护三个最大值/最小值。避免全排序。
			- 若是 limit 大的话，超过排序的 `sort_buffer_size` 时就会使用归并排序了。
		- 排序完毕按 limit 取数。
10. 执行 Limit 语句

## Varchar (11) 与 Int (11) 区别

Varchar 指定存储长度，int 指定显示长度。注意 Varchar 的 OrderBy 排序时使用 fixed_length 计算 col 长度。

## MVCC 的实现原理

- Undo 日志：记录数据的历史变化情况，通过 undo 日志可以追溯到以前的数据。
- ReadView
	- Mysql 的数据隐藏列中包含以下几个字段：roll_pointer，指向 undo 日志。Trx_id，指向这条日志产生的源事务 ID。Row_id，当没有主键是隐藏的主键 ID。
	- 在执行增/删/改的时候，每操作一次就会产生一条 undo 日志。Undo 日志包含上述的字段内容，根据 roll_pointer 就可以产生一条版本链。
	- 基于版本链的情况下，当查询操作产生的时候就会构造 ReadView 视图，从版本链中获取数据。生成 ReadView 视图时会包含以下内容：
		- M_ids：生成 ReadView 视图时活跃的事务 ID 列表。
		- Creator_trx_id：生成 ReadView 视图的事务 ID，即当前事务 ID。
		- Max_trx_id：生成 ReadView 视图时应该分配给下一个事务的 ID。
		- Min_trx_id：生成 ReadView 视图时活跃事务列表中最小的事务 ID。
	- MVCC 的规则如下：
		- 若当前版本链上数据的事务 ID 等于 Creator_trx_id，表示数据由当前事务产生，可读。
		- 若当前版本链上数据的事务 ID 大于 Max_trx_id，表示数据是视图创建之后产生的，不可读。往版本链往前找。
		- 若当前版本链上数据的事务 ID 小于 Min_trx_id，表示数据是视图创建之前产生的，可读。
		- 若当前版本链上数据的事务 ID 在 M_ids 列表中
			- 事务未提交：不可读。
			- 事务已提交
				- RC 级别下，数据可读。
				- RR 级别下，需要保持可重复读的特性，因此不可读。有一种特殊情况，若当前事务先对其进行更新操作，更新会触发当前读获取到最新数据更新。更新完之后该数据事务 ID 会变成当前事务 ID，当前事务就可读到了。

## Mysql 的锁

### 锁分类

- 按范围分类
	- 数据库锁：对数据库加锁。
		- `Flush tables with read lock (FTWRL)`，使数据库处于只读状态
		- 如果只是备份的话可以使用 `mysqldump–single-transaction` 来保证隔离型的读。注意使用这个语句需要所有数据表都是 InnoDB 引擎的。
		- 使用 `set global readonly=true` 的方式。这种方式有两个问题，其一是这个值通常用来处理一些其他情况，如是主库还是从库。另一个是修改 global 影响大，FTWRL 中断后自动释放锁，而 readonly 设置确不会。
	- 表锁
		- `lock tables ... read/write`，主动开启与释放锁。线程 A 中执行 `lock tables t1 read, t2 write;` 这个语句，则其他线程写 t1、读写 t2 的语句都会被阻塞。同时，线程 A 在执行 unlock tables 之前，也只能执行读 t1、读写 t2 的操作。连写 t1 都不允许，自然也不能访问其他表。
		- MDL (metadata lock)，是 Mysql5.5 版本增加的。会在操作一个表的时候自动加读/写锁。需要注意的是，在修改表结构的时候，**若前面有事务没释放锁，则修改表结构操作会阻塞。表结构操作阻塞后后续所有的请求都会阻塞。**
		- OnlieDDL执行过程
			1. 拿 MDL 写锁
			2. 降级成 MDL 读锁
			3. 真正做 DDL，这里不会阻塞读写操作
			4. 升级成 MDL 写锁
			5. 释放MDL锁
	- 行锁
	- 共享锁
	- 排他锁
- 按锁机制分类
	- 悲观锁
	- 乐观锁
- 按锁实现分类
	- S 锁
	- X 锁
	- IS 锁
	- IX 锁
	- Gap 锁
	- Next-key 锁
- 锁升级
	- 当行锁无法匹配数据时，会升级到表锁
	- 当索引记录超过整表 1/2 时，会走到全表查询。行锁变表锁。

### 死锁避免

- 设定超时时间
- 设定资源访问顺序
- 避免事务交叉
- 使用低隔离级别
- 主动死锁检测，在尝试获取锁的时候进行死锁检测。当发现自己的操作可能发生阻塞时，就主动回滚事务让其他事务执行。`innodb_deadlock_detect` 默认就是开启的。这里检测的时候不会扫描所有事务，只会扫描和当前线程操作资源相关的事务。

### 死锁解除

当线程持有锁时间超过 `innodb_lock_wait_timeout` 时，就主动放弃锁回滚事务。这个值默认是 50s。

### 两段锁协议

- 在 InnoDB 事务中，行锁是需要的时候加上去的，但并不是不需要了就立刻释放，而是等到事务结束才释放。这就是两阶段锁协议。
- 如果你的事务需要锁多个行，那么尽可能把造成锁冲突的，影响并发的语句往后放。

### 加锁过程

#### RU/RC 级别

- 主键索引
	- 等值查询
		加 X/S 锁，若是更新操作，会为涉及数据字段的二级索引加锁。若是删除操作，会对涉及数据的所有二级索引加锁。
	- 范围查询
		从满足条件的数据开始加锁，加锁规则与等值查询相同。当下一条数据不满足条件时，会先加锁再释放锁(5.7版本实验结果)。所以要注意锁争用问题。
- 普通索引
	- 等值查询
		加 X/S 锁，若是不满足索引下推条件需要回表，还会对主键索引进行加锁。这里不会出现对下一个不满足条件对数据加锁的情况。
	- 范围查询
		加锁同等值查询。若是查询语句，当下一个数据不满足条件时，会将二级索引加锁，但是不会释放锁。若是更新语句，则会先对二级索引和主键索引加锁，然后发现不满足条件又释放锁。(5.7 版本实验结果)。更新操作无法使用索引下推特性，因此才会对二级索引和主键索引都加锁。
- 无索引
	存储引擎扫描一行就对该行加 S/X 锁，返回 Server 层发现不满足条件后又释放锁。若是更新操作，还会对涉及到对二级索引加锁。
- 半一致性读
	在 RC 级别下，update 语句有个 `semi-consistent` 优化，当 update 语句碰见一个已经被锁住的行，会取出最新数据判断以下是不是满足条件。如果不满足条件就直接跳过，如果满足条件就进入锁等待。

#### RR 级别

- 加锁规则
	- 原则 1：加锁的基本单位是 next-key lock。Next-key lock 是前开后闭区间。Next-key 锁实际上是间隙锁+行锁组成的。
	- 原则 2：查找过程中访问到的对象才会加锁。
	- 优化 1：索引上的等值查询，给主键索引加锁的时候，next-key lock 退化为行锁。
	- 优化 2：索引上的等值查询，向右遍历时且最后一个值不满足等值条件的时候，next-key lock 退化为间隙锁。
	- 一个 bug：唯一索引上的范围查询会访问到不满足条件的第一个值为止。在 8.0.18 后已修复。
	- 利用索引的有序性，若一个数据的索引不在被加锁的区间内就不会受到影响。

- 加锁示例
	- 数据准备
		准备表 t (id, c, d)，其中 id 为主键，c 为普通索引，d 无索引。数据准备为 (0, 0)，(5, 5)，(10, 10)，(15, 15)，(20, 20)，(25, 25)

	- `update t set d = d+1 where id = 7;`
		会对主键索引 (5, 10) 区间加间隙锁。
	
	- `select id from t where c = 5 lock in share mode;`
		会对二级索引 c 加 Next-key 锁 (0, 5]与间隙锁 (5, 10)。由于索引覆盖，所以不会对主键索引加锁。Sql 查询字段若是改为 d，则回表会导致主键索引也被加锁。
	
	- `select * from t where id>=10 and id<11 for update;`
		会对主键索引行 10 以及 next-key 锁 (10, 15]进行加锁。其实这里发现 15 是不满足条件的，没必要进行加锁。在版本 8.0.19 上已经退化成间隙锁 (10, 15) 了。
	
	- `select * from t where c>=10 and id<11 for update;`
		这里 c 是普通索引，会对二级索引 c 加 next-key 锁 (5, 10]及 next-key 锁 (10, 15]进行加锁。同时对主键索引 10 加行锁。同 8.0.19 上后一个 next-key 锁会退化成间隙锁 (10, 15)。
		如果 c 是 uniqu 唯一索引的话，也还是 next-key 锁 (5, 10]及 next-key 锁 (10, 15]，前一个锁不会退化成行锁，只有主键索引会。测试版本为 8.0.20。
	
	- `select * from t where id>10 and id<=15 for update;`
		会对主键索引加 next-key 锁 (10, 15]及 (15, 20]进行加锁。8.0.18 后已优化唯一索引范围查询的加锁方式，只会有 (10, 15]的 next-key 锁。
	
	- 多增加一条数据 `insert into t values(30,10,30);`
		- `delete from t where c = 10;`
			此时存在两条 c=10 的数据，会对二级索引 c 加 (5: 5, 10: 10]，(10: 10, 10: 30]，(10: 30, 15:15)，同时对主键索引 5，10，30，15 加行锁。
		- `delete from t where c = 10 limit 2;`
			由于多了 limit 条件，因此扫描到两行后就会结束。此时加锁情况为对二级索引 c 加 (5: 5, 10: 10]，(10: 10, 10: 30]，对主键索引 5，10，30 加行锁。所以删除时如果行数确定的话尽量加上 limit 条件，这样可以减少锁的范围。
		- `select * from t where c >= 15 and c <= 20 order by c desc for update;`
			会对二级索引 c 加 (20, 25]，(15, 20]，(10, 15]，(5, 10]next-key 锁，同时对主键索引 10, 15, 25 加行锁。在 8.20 版本二级索引 c (20, 25]已优化为 (20, 25)，且主键索引无 25 的行锁。
			原因是因为这是倒序排序，所以索引会从后往前扫。扫描数据 15 时会发现仍满足条件，因此继续往前扫描一条数据，所以就对 10 也加上了锁。

	- 事务 A 执行 `select c from t where c > 5 for update;`，而后事务 B 先执行 `update t set c = 1 where c = 5`，之后再执行 `update t set c = 5 where c = 1;`
		首先 A 执行时会对二级索引 c 加 (5, 10], (10, 15], (15, 20], (20, 25], (25, supermum) 锁。事务 B 执行第一条语句时，c=5 列无锁，因此可以执行。但是执行后事务 A 的锁范围蔓延了，会变成 (1, 10)。之后事务 B 再次执行时，将 c=1 改为 c=5，更新操作其实是一个先增后删的操作，因此增加 c=5 这一列时就会被阻塞。

	- 死锁的例子
		![](https://varg-my-images.oss-cn-beijing.aliyuncs.com/img/20220513130251.png)
		事务 A 加了 (5, 10]和 (10, 15) 的锁，事务 B 加 (5, 10]的锁时失败阻塞，事务 A 再次插入时进入死锁状态。原因是因为 next-key 锁实际上是由间隙锁+行锁组成的。所以 B 加锁时其实是先加 (5, 10) 的间隙锁，成功，后加行锁是阻塞的。而事务 A 再次插入时被事务 B 的间隙锁锁住，因此阻塞进入死锁。

## 一条 SQL 执行慢的原因

- 偶尔慢
	- 数据库在刷新脏页
		- Redo 日志满了
		- 内存满了
		- MySql 正常刷新脏页
		- 正在关机
		- 脏页刷新的快慢和 Myql 的 iops 变量设置与当前脏页比例有关。
	- 获取不到锁
		- 可以通过 `show processlist` 来查看是否有阻塞表锁的线程。
		- 可以通过`select * from t sys. Innodb_lock_waits where locked_table=\`'test'.'t\'\`\G\`来查看锁阻塞情况。
	- 查询是快照读，有事务进行了大量更新操作没提交，产生大量 undo 日志。快照读需要解析这些 undo 日志因此耗时长。
	- 机器性能消耗
		比如突然QPS暴涨，导致Mysql压力过大
- 一直慢
	- 没正确使用索引
		- 联合索引使用了范围语句导致没用上
		- 使用了函数计算导致没用上。如 month () 这类。当两个表连接是，字段类型不同。如 `t1.a = t2.b`，, t1. A 的编码是 utf-8，, t2. B 的编码是 utf8mb4，此时 t1. A 会发生隐式函数计算 `CONVERT(t1.a USING utf8mb4) = t2.b;` 而导致无法使用索引。
		- 隐式类型转换导致没用上，比如 `.. where c = 1`，若 c 是字符串类型，相当于隐式执行了 `CAST(c AS signed int)` 这个转换。而如果索引是数值类型条件是字符串则不会有这个情况。
	- 索引没建
	- 由于数据库原因导致索引失效。如是否使用临时表，是否排序，估算的索引扫描行数等。

## Count 的区别

- Count 是扫描表中有多少条数据，然后将数据行数求和返回结果的。为什么不缓存一个表的记录数这样一个字段呢？因为每个事务可能查到不同的条数。
- Count 的各个区别
	- Count (\*)，取出一条数据就 + 1，这是 Mysql 官方的优化方式。
	- Count (1)，取出一条数据就 + 1，这是人为操作的优化方式。
	- Count (field)，取出一条数据的 field 字段，若字段不为空，则 +1，否则不加。
	- (0, 0), (5, 5), (10, 7) (10, 10)

## 数据库性能瓶颈优化

- 设置 `binlog_group_commit_sync_delay` 和 `binlog_group_commit_sync_no_delay_count` 参数，减少 binlog 的写盘次数。这个方法是基于“额外的故意等待”来实现的，因此可能会增加语句的响应时间，但没有丢失数据的风险。
- 将 `sync_binlog` 设置为大于 1 的值（比较常见是 100~1000）。这样做的风险是，主机掉电时会丢 binlog 日志。
- 将 `innodb_flush_log_at_trx_commit` 设置为 2。这样做的风险是，主机掉电的时候会丢数据。

## Mysql 的高可用

### 主备模式

![](https://varg-my-images.oss-cn-beijing.aliyuncs.com/img/20220514143924.png)

在状态 1 中，虽然节点 B 没有被直接访问，但是依然建议把节点 B（也就是备库）设置成只读（readonly）模式。这样做，有以下几个考虑：
- 有时候一些运营类的查询语句会被放到备库上去查，设置为只读可以防止误操作；
- 防止切换逻辑有 bug，比如切换过程中出现双写，造成主备不一致；
- 可以用 readonly 状态，来判断节点的角色。

你可能会问，把备库设置成只读了，还怎么跟主库保持同步更新呢？这个问题，不用担心。因为 readonly 设置对超级 (super) 权限用户是无效的，而用于同步更新的线程，就拥有超级权限。

主备的流程：

![](https://varg-my-images.oss-cn-beijing.aliyuncs.com/img/20220514144050.png)

主库接收到客户端的更新请求后，执行内部事务的更新逻辑，同时写 binlog。备库 B 跟主库 A 之间维持了一个长连接。主库 A 内部有一个线程，专门用于服务备库 B 的这个长连接。

一个事务日志同步的完整过程是这样的：
- 在备库 B 上通过 change master 命令，设置主库 A 的 IP、端口、用户名、密码，以及要从哪个位置开始请求 binlog，这个位置包含文件名和日志偏移量。
- 在备库 B 上执行 start slave 命令，这时候备库会启动两个线程，就是图中的 io_thread 和 sql_thread。
- Io_thread 负责与主库建立连接。主库 A 校验完用户名、密码后，开始按照备库 B 传过来的位置，从本地读取 binlog，发给 B。
- 备库 B 拿到 binlog 后，写到本地文件，称为中转日志（relay log）。
- Sql_thread 读取中转日志，解析出日志里的命令，并执行。这里需要说明，后来由于多线程复制方案的引入，sql_thread 演化成为了多个线程。
- 对于后续主库产生的新日志，就推送给备库执行。
基于 binlog 进行数据备份。Binlog 有三种格式：
- Statement：基于SQL语句级。
- Row：基于SQL改变数据级。
- Mixed：根据 SQL 情况，看是使用 Statement 级别还是 Row 级别。

### 主备延迟

对于主库上发生的更改，延迟了一段时间才到达从库。从库在执行当前事务时，可以在事务的 binlog 日志中看到该事务在主库中执行的时间。通过这个时间与系统时间的插值，就可以得到主备之间的延迟时间，称之为 `seconds_behind_master`。

主备延迟产生的情况可能如下：
- 从库配置低于主库，导致执行慢。
- 从库压力大，在从库上可能有许多其它的操作。如数据分析查询之类，影响同步速度。针对这种，可以进行一主多从的配置来分摊从库压力，或者将部分逻辑迁移到其它组件中，例如使用 Hadoop 来进行数据统计。
- 大事务，当有大事务时，事务提交才会同步给从库。因此事务执行时间长的话也会导致从库同步慢。
- 大表 DDL，影响类似于大事务。对于计划内的 DDL，推荐使用 gh-ost 方案。
- 备库的并行复制能力。
- 若需要迫切的提升从库的读写能力，可以进行以下策略的优化：
	- 从库开启 writeset
	- 将 `sync_binlog` 改为 0，`innodb_flush_log_at_trx_commit` 改为 2 提升写数据能力。

### 主备切换策略

![](https://varg-my-images.oss-cn-beijing.aliyuncs.com/img/20220514154847.png)

- 可靠性优先策略：
	- 判断当前从库的 `seconds_behind_master` 是否小于某个值，不小于就一直重试，小于开始进行主备切换。
	- 将主库改为只读状态。
	- 判断从库的 `seconds_behind_master` 是否为 0，不为 0 等待知道变为 0。
	- 将从库状态改为读写。
	- 请求切换到从库。
	
	在从库提升为读写这段期间服务不可用，这是为了保证可靠性做出的妥协。主库异常时，若从库存在未同步完的数据，此时从库也无法切换。

- 可用性优先策略
	- 不等到从库同步完主库的数据就直接将从库改为主库，接受读写请求。
	- 这种可能会导致数据不一致的情况，因为从原来主库同步的数据可能与新写入的数据发生冲突。
	- 如果使用该模式，binlog 建议使用 row 格式的。这样可以尽可能减少数据冲突的情况，也能尽可能早的发现数据错误的情况。

### 备库日志重放

当备库接收到主库的 binlog 日志后，需要进行重放操作。Mysql 最开始的版本提供的是单线程的重放模式，当主库日志非常多或者主库大事务阻塞之后提交给从库，那么这时候就会造成主从之间的数据延迟增大。为了改善这一情况引入了并行复制的能力。

并行复制采用了以下的规划：
- Coordinator 事务协调者，负责读取日志与将日志转发给后续的日志处理线程。协调者在分发日志时，需要注意以下要求：
	- 不能造成数据破坏，更新同一行的数据必须分发给同一个 worker。
	- 不能造成事务破坏，同一个事务操作必须分发给同一个 worker。
- Worker 日志重做者，负责对接受到的日志进行重放操作。

事务分发协调算法：

- 按库按表分发：对于同一个库/表操作的分发给同一个 worker，这样就避免了改动同一个库表。但是如果存在热点库/表，极端情况只有一个库/表的情况下，那么会退化成单线程模式。
	- 按表分发时，可进行以下规则判断：
		- 若当前事务涉及表没有其它 worker 在操作，可直接分发给一个空闲的 worker。
		- 若当前事务涉及表有一个 worker 在操作，直接分发给这个 worker。
		- 若当前事务涉及表有多个 work，等待。

- 按行分发策略
	- 针对事务影响的行进行分发，需要注意不仅仅从主键维度考虑，还需要从其它索引的维度考虑，一条数据可能会有多个索引。
	- 以行为维度binlog日志解析时会占用更多的计算资源。

- 按组提交是 CommitId 分发策略
	- 对于同一组提交的事务，其数据操作一定不会出现冲突。若冲突，则必然会等到前一个操作提交后后一个事务才可继续操作。
	- 基于这一个策略，所以可以对同一组内提交的事务分发给不同的 worker，当然还是得注意同一个事务的是不能分开的。
	- 对于 Mysql 来说，其实不一定需要等到 Commit 标记才认为事务没有冲突，在 redolog 的 prepare 阶段就可以确认了。当到达 prepare 阶段，就代表已经通过了锁的检测，所以可以分开进行操作了。因此可以考虑优化 `binlog_group_commit_sync_delay` 与 `binlog_group_commit_sync_no_delay_count` 这两个参数的配置来控制主从之间同步的效率。

- 按 WRITESET 分发策略
	在 Mysql5.7.22 的版本增加了一个新的策略，该策略有以下几种选择：
	- COMMIT_ORDER：基于 prepare 和 commit 来判断是否可以并行。
	- WRITESET：对事务涉及的每一行，计算这一行的 hash，组成集合 writeset。若两个事务没有操作同一行，则认为可以并行。
	- WRITESET_SESSION：在 WRITESET 的基础上增加了一个限制，主库上存在先后关系的事务从库上也要保证这个顺序。
	
	为了唯一标识，这个 hash 值是通过“库名 + 表名 + 索引名 + 值”计算出来的。如果一个表上除了有主键索引外，还有其他唯一索引，那么对于每个唯一索引，insert 语句对应的 writeset 就要多增加一个 hash 值。Writeset 是在主库生成后直接写入 binlog 中的，因此不会额外占用从库的计算资源，这占用的是主库的计算资源。

	对于数据上没有主键或存在外键约束的场景，WRITESET 策略也是没法并行的，也会暂时退化为单线程模型。

	可以通过数据库的配置 `binlog-transaction-dependency-tracking` 来决定是否开启 WRITESET 策略。

### 从库拉取主库数据

现在的数据库架构大多都是一主多从架构，那么这些从库如何拉取主库的数据呢？在主库发生切换的时候，从库基于什么规则拉取才能做到数据一致呢？
![](https://varg-my-images.oss-cn-beijing.aliyuncs.com/img/20220514175012.png)
![](https://varg-my-images.oss-cn-beijing.aliyuncs.com/img/20220514175033.png)

- 基于 binlog 的 position 拉取
	1. 等待新主库 A’ 把中转日志（relay log）全部同步完成。
	2. 在 A’ 上执行 show master status 命令，得到当前 A’ 上最新的 File 和 Position。
	3. 取原主库 A 故障的时刻 T。
	4. 用 mysqlbinlog 工具解析 A’ 的 File，得到 T 时刻的位点。
	
	这样得到的位点并不一定准确，当时刻 T 时若主库 A 产生了 binlog 发给从库，后续从库会接受到这个日志。而时刻 T 从 A‘上读取位点的时候还不包含这个日志，因此这个日志就可能被重复执行。
	
	对于插入操作，就会抛出主键重复错误，因此主备切换时通常要跳过这些错误。跳过作物的常用方法有：
	- 主动跳过一个事务：`set global sql_slave_skip_counter=1;`
	- 跳过一些指定类型错误：`slave_skip_errors`，如 1062 是唯一键冲突错误，1032 是删除时找不到行错误。这种直接跳过指定错误的方法，针对的是主备切换时，由于找不到精确的同步位点，所以只能采用这种方法来创建从库和新主库的主备关系。等主备同步完需要切换回去。

- GTID 算法
	由上可以看到，通过位点的方式同步数据并不准确，而且还要处理同步过程中的错误。在 Mysql5.6 版本引入了 GTID，Global Transaction Identifier，全局事务 ID。GTID 由两部分组成：server_uuid: gno，server_uuid 在 mysql 启动时生成，geo 在事务提交时自增。
	
	在 GTID 模式下，每个事务都会与一个 GTID 对应。这个 GTID 有两种生成方式，取决于 session 中 gtid_next 的值：
	- `gtid_next=automatic`
		使用默认自增值，在事务提交时 Mysql 会自动自增生成一个 GTID 并分配给该事务。同步将生成的 GTID 写入到 Mysql 的 GTID 集合与该事务的 binlog 中。
	- Session 指定值
		- 若指定值已存在 Mysql 实例的 GTID 集合，则该事务被忽略。
		- 不存在，将 GTID 分配给该事务并执行。一个 current_gtid 只能给一个事务使用。这个事务提交后，如果要执行下一个事务，就要执行 set 命令，把 gtid_next 设置成另外一个 GTID 或者 automatic。

	有了 GTID 算法，在进行主备切换时就无需指定位点了。同步时从库将自己的 GTID 集合传递给主库，主库与自己的 GTID 集合做差集。对于差集结果有以下处理：
	- 差集中包含不在主库中的 GTID，代表主库已经将该 binlog 给删除了，返回错误。
	- 若全部包含，就将需要的 binlog 发送给从库。
	- 这个逻辑里面包含了一个设计思想：在基于 GTID 的主备关系里，系统认为只要建立主备关系，就必须保证主库发给备库的日志是完整的。因此，如果实例 B 需要的日志已经不存在，A’就拒绝把日志发给 B。这跟基于位点的主备协议不同。基于位点的协议，是由备库决定的，备库指定哪个位点，主库就发哪个位点，不做日志的完整性判断。
	- 对于有问题的事务日志，就可以通过 `set gtid_next='id';` 将其排除，不影响主备流程。

### 读写分离如何保证读数据准确性？

![](https://varg-my-images.oss-cn-beijing.aliyuncs.com/img/20220514205909.png)

读写分离的方案：
- 客户端主动做负载均衡：这种情况下将数据库连接放在客户端，由客户端选择从哪个数据库查询。这种模式需要客户端管理配置，并且对数据库配置信息改动时需要增加处理机制。
- 中间层代理：客户端与中间代理层交互，代理层分发请求到不同数据库。这种模式会略微损失一些行能，但客户端侧就无需关注过多关于数据库的细节。

读写分离，写操作发生在主库，读操作发生在从库。当主库的变更日志未到达从库之前，从库读到的都不是最新的数据。解决这一问题有以下几种办法：

- 强制走主库读
	对于必须拿到最新数据的请求，从主库查。可以读到旧数据的请求，从从库查。这个方案的问题是当所有请求都无法接受读到旧数据时，所有请求都会落到主库中。

- Sleep 方案
	针对主从之间的延迟，估算一个时间，然后读请求产生的时候先 sleep 一下，以此来保证主从同步。这个方案的问题是时间估算并不一定准确。或者另一个思路是将这个延迟坐在用户端，让前端先直接将数据展示到页面而不是从数据库查，下次刷新时再从数据库查。

- 判断主备无延迟方案
	在查询从库时，判断当前主从是否有延迟。若当前主从无延迟，就可以从从库读。判断延迟有以下几种方案：
	- 利用 `show slave status;` 返回的 `seconds_behind_master` 查看，若这个值不为 0，则需要等待。
	- 对比点位判断延迟
		Master_Log_File 和 Read_Master_Log_Pos，表示的是读到的主库的最新位点；Relay_Master_Log_File 和 Exec_Master_Log_Pos，表示的是备库执行的最新位点。如果 Master_Log_File 和 Relay_Master_Log_File、Read_Master_Log_Pos 和 Exec_Master_Log_Pos 这两组值完全相同，就表示接收到的日志已经同步完成。
	- 对比 GTID 集合判断延迟
		Auto_Position=1 ，表示这对主备关系使用了 GTID 协议。Retrieved_Gtid_Set，是备库收到的所有日志的 GTID 集合；Executed_Gtid_Set，是备库所有已经执行完成的 GTID 集合。如果这两个集合相同，也表示备库接收到的日志都已经同步完成。
			
	需要注意的一点是 `show slave status;` 这只能表示当前从库收到的日志的处理情况，对于那些**主库还未同步到从库的日志，这段延时从库是判断不出来的**。`seconds_behind_master` 是计算收到的日志与当前时间的差值，这个日志并不一定是主库最新的日志。同理位点和 GTID 集合也不一定是主库最新的数据。
	**同时还有另一点是若主库源源不断的有日志过来，那么这个延迟就一直不为 0**。

- semi-sync 半同步方案
	半同步方案设计如下：
	1. 事务提交的时候，主库把 binlog 发给从库。
	2. 从库收到 binlog 以后，发回给主库一个 ack，表示收到了。
	3. 主库收到这个 ack 以后，才能给客户端返回“事务完成”的确认。

	采用半同步方案，就能确保至少有一个从库是最新的数据。如果是一主一从，那么读延迟就可以解决了，如果一主多从的话，那么其它从库还是不能保证读取到最新数据。

- 等主库位点方案
	`select master_pos_wait(file, pos[, timeout]);` 可以从主库查询位点信息，各参数作用如下：
	- File，pos：主库文件名和位置。
	- Timeout：从主库执行该命令的超时时间。
	
	返回结果可能有以下几种：
	- NULL：发生异常
	- -1：timeout 时间
	- 0：该 pos 位置的事务已在从库执行
	- 大于0的整数M：从命令开始执行，到应用完 file 和 pos 表示的 binlog 位置，执行了多少事务。

	基于这个命令，可以进行如下操作：
	1. 执行完更新语句后从主库获取当前的 File 和 position。
	2. 选定一个从库执行上面的查询语句。
	3. 如果返回值>=0，就在从库上执行该查询。
	4. 否则到主库查询。

	![](https://varg-my-images.oss-cn-beijing.aliyuncs.com/img/20220514211034.png)

- 等主库 GTID 方案
	如果开启了 GTID 模式，则 GTID 也有类似的查询。`select wait_for_executed_gtid_set(gtid_set, 1);` 用于实现 GTID 的等待查询。
	
	对于 GTID 的获取，可以主动查询，也可以在执行完请求后让数据库直接返回。具体做法如下：
	1. 将参数 `session_track_gtids` 设置为 `OWN_GTID`。
	2. 通过 API 接口 mysql_session_track_get_first 从返回包解析出 GTID 的值。
	3. 或者在客户端代码调用 `mysql_session_track_get_first;` 函数。

### 可用性监控

- 外部监控
	需要注意的是内部监控有随机性，监控的时刻正常并不一定代表过去一直正常。
	- `select 1;` 判断
	通过 select 1 可以判断是否可以连接上数据库，但是无法判断当前数据库能否执行请求。比如当前数据库并发查询连接数已到了最大值 `innodb_thread_concurrency`，后续的请求都会阻塞，但是 select 1 仍会正常返回。
	并发连接与并发查询不一样，并发连接可以很大，如上千个查询同时进入数据库。但是并发查询不同，并发查询是数据库真正在执行查询的请求，其它未执行的会等待。比如线程锁等待后，并发查询数减一，但并发连接不变。
- 查表判断
	可以建立一个系统表，然后查询该系统表数据，看是否能正常返回。使用这个方法，我们可以检测出由于并发线程过多导致的数据库不可用的情况。但是无法检查空间占用达到 100%而无法写入的场景。
- 更新判断
	通过更新系统表，来判断更新请求能否正常执行。对于一主一丛或一主多从，可以直接更新系统表就行了。但是如果是一主多从的话，需要注意主与主之间 binlog 会互传，所以会出现更新失败的情况。因此两主之间的数据 id 需要做到差异，如主键 ID 设置为 `@@server_id`。
- 内部监控
	MySQL 5.6 版本以后提供的 `performance_schema` 库，就在 `file_summary_by_event_name` 表里统计了每次 IO 请求的时间。开启这个功能数据库行能会下降 10%左右。`update setup_instruments set ENABLED='YES', Timed='YES' where name like '%wait/io/file/innodb/innodb_log_file%';`，可以通过这个命令开启监控功能。

## 数据备份与恢复

- 误删行数据，可以利用 binlog 反向操作还原数据。对于此类情况，考虑使用稳定的工具进行日志回放，回放过程优先找个临时库测试与验证。
- 误删库/表
	- 取出数据库的备份记录，然后取出日志备份，将备份记录之后的日志进行回放操作。
	- 取出备份记录，将其恢复出一个临时实例。然后将这个实例作为从库去同步数据。
- 预防措施
	- 延迟复制从库，可以保留一个从库采取延迟复制策略，通过 `CHANGE MASTER TO MASTER_DELAY = N` 命令，可以指定这个备库持续保持跟主库有 N 秒的延迟。
	- 完善的权限管理机制，SQL 执行规范，Review 流程等。

## Kill 语句的执行过程

Kill 语句分为两个：
- Kill query + 线程 ID
	该语句执行后，做了以下两件事情：
	1. 把 session B 的运行状态改成 THD :: KILL_QUERY (将变量 killed 赋值为 THD :: KILL_QUERY)。
	2. 给 session B 的执行线程发一个信号。
- Kill connection + 线程 ID

对于 kill，实际操作是按以下方式进行的：
1. 一个语句执行过程中有多处“埋点”，在这些“埋点”的地方判断线程状态，如果发现线程状态是 THD :: KILL_QUERY，才开始进入语句终止逻辑。
2. 如果处于等待状态，必须是一个可以被唤醒的等待，否则根本不会执行到“埋点”处。比如 IO 阻塞的话，就不会随便被唤醒。
3. 语句从开始进入终止逻辑，到终止逻辑完全完成，是有一个过程的。

Kill 语句执行后耗时长的原因
- 线程没有执行到判断线程状态的逻辑
- 终止逻辑耗时长。如执行大事务期间被 kill，需要回滚所有操作，比如删除中间的临时文件之类。
- 